{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nlvdEb8oUSdg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset,TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pdb\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_available = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n"
      ],
      "metadata": {
        "id": "a8EMkyqiYaoZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MGqzonD7Ua3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea6fafd-05e8-446f-a073-0deae56a335e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DIR = '/content/drive/My Drive/Brain Tumor Classification Project/dataSet/Testing' # test data folder\n",
        "TRAIN_DIR = '/content/drive/My Drive/Brain Tumor Classification Project/dataSet/Training' # train data folder\n",
        "CATEGORIES = [\"glioma\",\"meningioma\",\"notumor\",\"pituitary\"]\n",
        "\n",
        "# Hyperparameters\n",
        "hyparams = {\n",
        "      \"img_shape\": (224,224),\n",
        "      \"n_class\": 4,\n",
        "      \"learning_rate\": 0.001,\n",
        "      \"batch_size\": 16,\n",
        "      \"epochs\": 10\n",
        "  }\n"
      ],
      "metadata": {
        "id": "umzzfN0SYqRF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def one_hot_encoder(class_num):\n",
        "    one_hot = torch.zeros(4)\n",
        "    one_hot[class_num] = 1\n",
        "    return one_hot\n"
      ],
      "metadata": {
        "id": "U_ASPt4PJYoE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Resize(hyparams[\"img_shape\"], antialias=True),  # Explicitly set antialias to True\n",
        "      # Convert image to tensor\n",
        "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize if needed\n",
        "])\n",
        "def load_data(dir,device):\n",
        "    data = []\n",
        "    for category in CATEGORIES:\n",
        "        path = os.path.join(dir,category)  # create path\n",
        "        class_num = torch.tensor(CATEGORIES.index(category))  # get the classification\n",
        "        class_one_hot_vec = one_hot_encoder(class_num)\n",
        "        for img in tqdm(os.listdir(path)):\n",
        "\n",
        "          image = cv2.imread(os.path.join(path,img))  # convert to array and read grayscale images - 1 chanel\n",
        "          new_array = transform(np.array(image)) # resize to normalize data size\n",
        "          data.append([new_array, class_one_hot_vec])  # add this to our training_data\n",
        "\n",
        "    return data\n",
        "\n"
      ],
      "metadata": {
        "id": "s3wLbyPyZRAk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = load_data(TRAIN_DIR,device)\n",
        "train_data, val_data = train_test_split(data, test_size=0.2)\n",
        "\n",
        "test_data = load_data(TEST_DIR,device)\n",
        "\n",
        "train_data = DataLoader(dataset=train_data, batch_size=hyparams[\"batch_size\"], shuffle=True)\n",
        "val_data = DataLoader(dataset=val_data, batch_size=hyparams[\"batch_size\"], shuffle=True)\n",
        "test_data = DataLoader(dataset=test_data, batch_size=hyparams[\"batch_size\"], shuffle=True)\n"
      ],
      "metadata": {
        "id": "qBhTwqtnchAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba10bdd4-c05c-4672-f0c7-e1590da42332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1321/1321 [01:15<00:00, 17.57it/s]\n",
            " 34%|███▍      | 453/1333 [01:12<01:16, 11.55it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot 4*4 images for train_data\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "images, labels = next(iter(train_data))\n",
        "\n",
        "# Plot the images in a 4x4 grid\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(images[i].permute(1, 2, 0))\n",
        "    plt.title(CATEGORIES[labels[i].argmax()])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Zv0fVz1J53Vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super(ResNet18, self).__init__()\n",
        "\n",
        "        # Load the pre-trained ResNet18 model\n",
        "        self.base_model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "        # Modify the last fully connected layer to match the number of classes\n",
        "        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through the base model\n",
        "        x = self.base_model(x)\n",
        "\n",
        "        # Apply softmax activation function\n",
        "        x = F.softmax(x, dim=1)\n",
        "\n",
        "        # Return the output\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "fzFsrFHdS_Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = ResNet18().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=hyparams[\"learning_rate\"])\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "KWXsIZL5A-EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def train(train_data, model, criterion, optimizer):\n",
        "    train_error = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, data in enumerate(tqdm(train_data)): # tqdm for Progress bar\n",
        "        images, labels = data\n",
        "\n",
        "        images = images.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_error += loss.item() * images.size(0) # gives the total contribution of the loss from all images in the batch\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for i,pred in enumerate(predicted):\n",
        "            if labels[i][pred] == 1:\n",
        "              correct += 1\n",
        "\n",
        "\n",
        "    return train_error / len(train_data.dataset), correct / len(train_data.dataset)\n",
        "\n"
      ],
      "metadata": {
        "id": "M5nTMkxrFKoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_data, model, criterion):\n",
        "    test_error = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(tqdm(test_data)): # tqdm for Progress bar\n",
        "            images, labels = data\n",
        "\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            labels = labels.to(device)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_error += loss.item() * images.size(0) # gives the total contribution of the loss from all images in the batch\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            for i,pred in enumerate(predicted):\n",
        "              if labels[i][pred] == 1:\n",
        "                correct += 1\n",
        "\n",
        "\n",
        "    return test_error / len(test_data.dataset), correct / len(test_data.dataset)\n",
        "\n"
      ],
      "metadata": {
        "id": "tE9DmOeBKYp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, hyparams['epochs'] + 1): # start for 1 - for nicer log\n",
        "    # train\n",
        "    train_error,train_accuracy = train(train_data, model, criterion, optimizer)\n",
        "    print(\"train_error \" + str(train_error))\n",
        "    print(\"train accuracy \" + str(train_accuracy))\n",
        "    # validate\n",
        "    val_error,val_accuracy = test(val_data, model, criterion)\n",
        "    print(\"val_error \" + str(val_error))\n",
        "    print(\"val accuracy \" + str(val_accuracy))"
      ],
      "metadata": {
        "id": "D2W0_fKlBmrm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}