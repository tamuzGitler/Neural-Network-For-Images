{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heJO4vEqi3U7"
      },
      "source": [
        "## ðŸª„ Install `wandb` library and login\n",
        "\n",
        "\n",
        "Start by installing the library and logging in to your free account.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WMY2Vy8Xi3U7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d26723-a60d-4ce9-921d-3006170ade5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.23.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t1BpNhjui3U8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898043a0-8035-40fa-e73d-9d9fbee9bf86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtamuz1212\u001b[0m (\u001b[33mnn-for-images\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# # Log in to your W&B account\n",
        "import wandb\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "id": "HhXHAm0KRuvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f19a7291-ac79-453a-d359-e2d3d1c27941"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import pdb\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from keras.datasets import mnist\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.init as init\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "# new \n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import os\n",
        "import torchvision.transforms.functional as TF\n",
        "\n"
      ],
      "metadata": {
        "id": "qqXsL_cWnoe-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize DCGAN Parameters\n",
        "\n",
        "# Model parameters (feature map refers to the output of a specific layer in the network)\n",
        "latent_dim = 100\n",
        "out_channel = 1\n",
        "random.seed(999)\n",
        "torch.manual_seed(999)\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 64\n",
        "num_epochs = 15\n",
        "inversion_num_epochs = 15\n",
        "\n",
        "lr = 0.0002\n",
        "betas = (0.5, 0.999)\n",
        "num_of_updates = 5\n",
        "\n",
        "# TO use GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "fixed_noise = torch.randn(16, latent_dim, device=device) \n"
      ],
      "metadata": {
        "id": "3aIcpfT0vu-Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the MNIST dataset\n",
        "\n",
        "\n",
        "# transformer that  converters the data to PyTorch tensors and normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()])\n",
        "#   transforms.Normalize((0.5, ), (0.5,))\n",
        "   \n",
        "# Download and load the training data\n",
        "train_set = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "train_loader_1_batch_size = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "test_set = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vv7Z_Ptvn1eB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Generator and Descriminator\n",
        "\n",
        "\n",
        "\n",
        "# took from DCGAN tutorial for weights inition\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "# Generator - create new data that resembles the real data\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim ,out_channel):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Define Generators layers seperetly to print dimensions easily\n",
        "        self.linear_layer = nn.Sequential(\n",
        "            nn.Linear(latent_dim,128),\n",
        "            nn.Linear(128,128*3*3), \n",
        "            nn.ReLU(0.2))\n",
        "        \n",
        "        self.reshape_linear_layer = nn.Unflatten(1, (128,3,3)) #unflattern\n",
        "\n",
        "        self.first_cnn_layer = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(True))\n",
        "\n",
        "        self.second_cnn_layer = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=2, padding =1, output_padding =1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(True))\n",
        "        \n",
        "        self.third_cnn_layer = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=32, out_channels=out_channel, kernel_size=3, stride=2, padding =1, output_padding =1),\n",
        "            nn.Sigmoid()\n",
        "        ) \n",
        "        \n",
        "        \n",
        "        # Init models weights \n",
        "        self.apply(weights_init)\n",
        "     \n",
        "    def forward(self, x):\n",
        "          # print(\"G\")\n",
        "          # print(x.shape)\n",
        "          x =  self.linear_layer(x) # [256, 100] -> [256, 128*3*3]\n",
        "          # print(x.shape)\n",
        "          x = self.reshape_linear_layer(x) #[256, 128*3*3] -> [256, 128, 3, 3]\n",
        "          # print(x.shape)\n",
        "          x =  self.first_cnn_layer(x) # [256, 128, 3, 3] -> [256, 64, 7, 7]\n",
        "          # print(x.shape)\n",
        "          x =  self.second_cnn_layer(x) # [256, 64, 7, 7] -> [256, 32, 14, 14]\n",
        "          # print(x.shape)\n",
        "          x =  self.third_cnn_layer(x) # [256, 32, 14, 14] -> [256, 1, 28, 28] in range [0,1]\n",
        "          # print(x.shape)\n",
        "          return x\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Define Discriminator layers seperetly to print dimensions easily\n",
        "\n",
        "        self.first_cnn_layer = nn.Sequential(\n",
        "            # Layer1 - Conv2d, (1,28,28) -> (32,14,14)\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),  # N, 64, 14, 14\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU())\n",
        "        self.second_cnn_layer = nn.Sequential(\n",
        "            # Layer2 - Conv2d, (32,14,14) -> (64,7,7)\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # N, 128, 7, 7\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU())\n",
        "        self.third_cnn_layer = nn.Sequential(\n",
        "            # Layer3 - Conv2d, (64,7,7) -> (128,4,4)\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0),  # N, 128, 7, 7\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU())\n",
        "        self.flat_and_linear_layer = nn.Sequential(\n",
        "            # Layer3 - fully connected, (128,7,7) \n",
        "            nn.Flatten(), # -> (128*3*3)\n",
        "            nn.Linear(128 * 3 * 3, 1024),   # (128*3*3) -> (1024)\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(),\n",
        "            # Layer4 - fully connected, (1024) -> (1)\n",
        "            nn.Linear(1024, 1),\n",
        "            nn.Sigmoid()) # remove sigmoid when using MSELoss\n",
        "\n",
        "        # Init models weights \n",
        "        self.apply(weights_init)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"D\")\n",
        "        # print(x.shape)\n",
        "        x = self.first_cnn_layer(x) # [256, 1, 28, 28] -> [256, 32, 14, 14]\n",
        "        # print(x.shape)\n",
        "        x = self.second_cnn_layer(x) # [256, 32, 14, 14] -> [256, 64, 7, 7]\n",
        "        # print(x.shape)\n",
        "        x = self.third_cnn_layer(x) # [256, 64, 7, 7] -> [256, 128, 3, 3]\n",
        "        # print(x.shape)\n",
        "        x = self.flat_and_linear_layer(x) # [256, 128, 3, 3] -> [256,1] in range [0,1]\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "4oCr-rxLywSG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zam3_U8B6pKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def plot_generated_img(G,fixed_noise):\n",
        "    with torch.no_grad():\n",
        "        # Reconstruct images from the fixed_noise\n",
        "        output = G(fixed_noise).cpu().detach()\n",
        "        img_grid = torchvision.utils.make_grid(output, nrow=4).numpy()\n",
        "        fig, ax = plt.subplots(figsize=(10, 10))\n",
        "        plt.imshow(np.transpose(img_grid, (1, 2, 0)))\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def plot_image(image):\n",
        "    image = image.detach().cpu().numpy()\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def plot_two_images(image1, image2):\n",
        "    image1 = image1.detach().cpu().numpy()\n",
        "    image2 = image2.detach().cpu().numpy()\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image1, cmap='gray')\n",
        "    ax1.set_title(\"G(Z)\")\n",
        "    ax1.axis(\"off\")\n",
        "    ax2.imshow(image2, cmap='gray')\n",
        "    ax2.set_title(\"Real Image\")\n",
        "    ax2.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
      ],
      "metadata": {
        "id": "7gY4Hlwvx08D"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train the network & Loss function\n",
        "# Init models\n",
        "G = Generator(latent_dim,out_channel).to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "# Init loss function and Optimizer\n",
        "criterion = nn.BCELoss()\n",
        "# criterion = nn.MSELoss() # L2 loss - least squares loss \n",
        "G_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=betas)\n",
        "D_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=betas)\n",
        "\n",
        "   \n",
        "def trainDCGAN(saturation):\n",
        "\n",
        "    # Start a new run to track this script\n",
        "    wandb.init(\n",
        "    # Set the project where this run will be logged\n",
        "    project=\"ex3-nn\", \n",
        "    # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
        "    name=f\"epochs: {num_epochs}, batch size: {batch_size}, lr: {lr}\")\n",
        "\n",
        "    # start timing\n",
        "    start_time = time.time()\n",
        "\n",
        "    # train model\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"##### Epoch {epoch} #####\")\n",
        "         # Enter Traininig mode\n",
        "        G.train()\n",
        "        D.train()\n",
        "\n",
        "        d_losses = []\n",
        "        g_losses = []\n",
        "\n",
        "        # Train\n",
        "        for data in train_loader:\n",
        "            real_images =  data[0].to(device)\n",
        "            \n",
        "            images_size = len(real_images)\n",
        "            # Init real\\fake predictions\n",
        "            real_pred = torch.ones(images_size).to(device) # predict that the images are real , shape of [batch_size]\n",
        "            fake_pred = torch.zeros(images_size).to(device) # predict that the images are generate by G, shape of [batch_size]\n",
        "\n",
        "            ##### Descriminator - multiple optimizations (maximize log(D(x)) + log(1 - D(G(z)))) #####\n",
        "            noise = torch.randn(images_size, latent_dim, device=device) \n",
        "            fake_images = G(noise)\n",
        "   \n",
        "            \n",
        "            # calc and save D loss - combination of real\\fake losses \n",
        "            real_loss = criterion(D(real_images).view(-1), real_pred)\n",
        "            fake_loss = criterion(D(fake_images.detach()).view(-1), fake_pred) # detach fake images\n",
        "\n",
        "            d_loss = (real_loss + fake_loss) \n",
        "\n",
        "            # zero the parameter gradients\n",
        "            D_optimizer.zero_grad()\n",
        "            d_loss.backward()\n",
        "            # update optimizer\n",
        "            D_optimizer.step()\n",
        "\n",
        "\n",
        "            ##### Generator - single optimization (maximize log(D(G(z)))) #####\n",
        "            # for i in range(num_of_updates):\n",
        "            output = D(fake_images).view(-1)\n",
        "            \n",
        "            # calc G loss\n",
        "            if saturation:\n",
        "                g_loss = -criterion(output, fake_pred)\n",
        "            else: \n",
        "                g_loss = criterion(output, real_pred) # none saturation - better results\n",
        "\n",
        "              # zero the parameter gradients\n",
        "            G_optimizer.zero_grad()  \n",
        "            g_loss.backward(retain_graph=True) #retain_graph=True\n",
        "            G_optimizer.step()\n",
        "            \n",
        "            # save losses\n",
        "            g_losses.append( g_loss.item())\n",
        "            d_losses.append(d_loss.item())\n",
        "            if saturation:\n",
        "                wandb.log({\"saturation Descriminator Loss\": d_loss.item(),\"saturation Generator Loss\":  g_loss.item()})\n",
        "            else:\n",
        "                wandb.log({\"Descriminator Loss\": d_loss.item(),\"Generator Loss\":  g_loss.item()})\n",
        "\n",
        "        # plot_generated_img(G,fixed_noise) # Plot generated images with the same noise to check progress\n",
        "\n",
        "    # calculate and print total time of training\n",
        "    end_time = time.time()\n",
        "    total_time = str(end_time - start_time)\n",
        "    print('Finished Training, it took:' + total_time + ' seconds')\n",
        "\n",
        "trainDCGAN(saturation=False)"
      ],
      "metadata": {
        "id": "VvNjMNECoyEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b501ecac-6b23-4788-c17c-54426ad8e4e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### Epoch 0 #####\n",
            "##### Epoch 1 #####\n",
            "##### Epoch 2 #####\n",
            "##### Epoch 3 #####\n",
            "##### Epoch 4 #####\n",
            "##### Epoch 5 #####\n",
            "##### Epoch 6 #####\n",
            "##### Epoch 7 #####\n",
            "##### Epoch 8 #####\n",
            "##### Epoch 9 #####\n",
            "##### Epoch 10 #####\n",
            "##### Epoch 11 #####\n",
            "##### Epoch 12 #####\n",
            "##### Epoch 13 #####\n",
            "##### Epoch 14 #####\n",
            "Finished Training, it took:238.15997314453125 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "LtBZ50QviXoh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Q2 - Model Inversion\n",
        "   \n",
        "def model_inversion(image):\n",
        "\n",
        "    # start timing\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Init loss function and Optimizer and z,  Remember - G is already pre-trained\n",
        "    z = torch.randn(1, latent_dim, device=device, requires_grad=True) \n",
        "    z_optimizer = torch.optim.RMSprop([z], lr=lr) # performce better than Adam Optimizer in this case\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Enter evaluation mode with G\n",
        "    G.eval()\n",
        "\n",
        "    for epoch in range(30001):\n",
        "        # if epoch % 100 == 0:\n",
        "        #     print(f\"##### Epoch {epoch} #####\")\n",
        "       \n",
        "        # reconstruct the images z\n",
        "        output = G(z).squeeze()\n",
        "    \n",
        "        # calculate loss\n",
        "        loss = criterion(output, image) # compare between G(z) to the real images\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        z_optimizer.zero_grad()\n",
        "        loss.backward() # calc gradients\n",
        "        # update optimizer\n",
        "        z_optimizer.step()\n",
        "\n",
        "        if epoch % 10000 == 0:\n",
        "            print(f\"##### Epoch {epoch} #####\")            \n",
        "            plot_two_images(output,image) # Plot generated images with the same noise to check progress\n",
        "\n",
        "    # calculate and print total time of training\n",
        "    end_time = time.time()\n",
        "    total_time = str(end_time - start_time)\n",
        "    print('Finished Training, it took:' + total_time + ' seconds')\n",
        "\n",
        "image = next(iter(test_loader))[0][0].squeeze().to(device)\n",
        "model_inversion(image)"
      ],
      "metadata": {
        "id": "URQmFVFvnFkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ helpers for Q3\n",
        "def add_gaussian_noise(image, mean=0, stddev=0.1):\n",
        "    device = image.device\n",
        "    noise = (torch.randn(image.size(), device=device) * stddev + mean)\n",
        "    noisy_image = torch.clamp(image + noise, 0, 1) # Normalize the noise samples to the range [0, 1]\n",
        "    return noisy_image\n",
        "\n",
        "def inpaint_image(image):\n",
        "    window_size = (8,8)\n",
        "    h, w = image.shape\n",
        "    inpainted_image = image.clone()\n",
        "\n",
        "    # calc maximum starting positions of the inpaiting window and randomly select starting position \n",
        "    max_h = h - window_size[0]\n",
        "    max_w = w - window_size[1]\n",
        "    start_h = random.randint(0, max_h)\n",
        "    start_w = random.randint(0, max_w)\n",
        "\n",
        "    # inpaint window region with black color\n",
        "    inpainted_image[..., start_h:start_h+window_size[0], start_w:start_w+window_size[1]] = 0\n",
        "\n",
        "\n",
        "    return inpainted_image\n"
      ],
      "metadata": {
        "id": "QpMMUOinoQr7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Q3 - Image restoration\n",
        "   \n",
        "def image_restoration(image, denoising):\n",
        "    image = image.squeeze()\n",
        "\n",
        "    # start timing\n",
        "    start_time = time.time()\n",
        "    if denoising:\n",
        "        blurred_image = add_gaussian_noise(image).squeeze()\n",
        "        criterion = nn.MSELoss()\n",
        "        plot_image(blurred_image)\n",
        "\n",
        "    else:\n",
        "        # image = image.squeeze()\n",
        "        blurred_image = inpaint_image(image)\n",
        "        criterion = nn.L1Loss()\n",
        "\n",
        "\n",
        "    # Init and Optimizer and z,  Remember - G is already pre-trained\n",
        "    z = torch.randn(1, latent_dim, device=device, requires_grad=True)\n",
        "    z_optimizer = torch.optim.Adam([z], lr=lr,betas=betas) # performce better than Adam Optimizer in this case\n",
        "\n",
        "    # Enter evaluation mode with G\n",
        "    G.eval()\n",
        "\n",
        "    for epoch in range(200001):\n",
        "        output = G(z).squeeze()\n",
        "        if denoising:\n",
        "            blurred_output = add_gaussian_noise(output).squeeze()\n",
        "        else:\n",
        "            blurred_output = inpaint_image(output)\n",
        "\n",
        "        loss = criterion(blurred_output, blurred_image) # compare between G(z) to the real images\n",
        "        # zero the parameter gradients\n",
        "        z_optimizer.zero_grad()\n",
        "        loss.backward() # calc gradients\n",
        "        # update optimizer\n",
        "        z_optimizer.step()\n",
        "\n",
        "        if epoch % 25000 == 0:\n",
        "            print(f\"##### Epoch {epoch} #####\")\n",
        "            if denoising:  \n",
        "                plot_two_images(output,image) # Plot generated images with the same noise to check progress\n",
        "            else:\n",
        "                plot_two_images(output,blurred_image) # Plot generated images and inpainting  to check progress\n",
        "\n",
        "    # calculate and print total time of training\n",
        "    end_time = time.time()\n",
        "    total_time = str(end_time - start_time)\n",
        "    print('Finished Training, it took:' + total_time + ' seconds')\n",
        "\n",
        "    \n",
        "image = (next(iter(test_loader))[0][0]).to(device)\n",
        "plot_image(image.squeeze())\n",
        "image_restoration(image,denoising=False)\n"
      ],
      "metadata": {
        "id": "qxHO_WmRTjbx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}